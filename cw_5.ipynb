{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __WSI - ćwiczenie 5.__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Sztuczne sieci neuronowe__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Treść ćwiczenia__\n",
    "\n",
    "- Celem cwiczenia jest implementacja perceptronu wielowarstwowego oraz wybranego algorytmu\n",
    "optymalizacji gradientowej z algorytmem propagacji wstecznej.\n",
    "- Nastepnie nalezy wytrenowac perceptron wielowarstwowy do klasyfikacji zbioru danych wine\n",
    "(https://archive.ics.uci.edu/ml/datasets/wine). Zbiór ten dostepny jest w pakiecie scikitlearn\n",
    "(sklearn.datasets.load wine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, precision_recall_curve, auc, RocCurveDisplay, PrecisionRecallDisplay, recall_score, precision_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from seaborn import heatmap\n",
    "import plotly.express as px\n",
    "from math import log, inf, e, tanh\n",
    "from sklearn.utils import resample, shuffle\n",
    "\n",
    "RNG = np.random.default_rng()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cele: \n",
    "- perceptron wielowarstwowy, implementacja ze zmienną ilością warstw głębokich oraz zmienną ilością długości wektora neuronów\n",
    "- kilka algorytmów optymalizacji wag sieci (gradient prosty, SGD, algorytm ewolucyjny??)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zadania:\n",
    "1. model sieci\n",
    "2. propagacja wsteczna\n",
    "3. optymalizacja wag"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Weight matrix per layer:__\n",
    "\n",
    "$$\n",
    "\\theta^{l}=\n",
    "\\left[\\begin{array}{ccc}\n",
    "\\omega_{1,1}& \\cdots&\\omega_{1,k+1}\\\\\n",
    "\\vdots&\\ddots&\\vdots\\\\\n",
    "\\omega_{n,1}&\\cdots&\\omega_{n,k+1}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "where  $ \\omega_{i,j} $ is the $j$-th weight of the $i$-th neuron (in layer $l$), and $ \\omega_{i,k+1} $ is its bias"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Matrix of layers:__\n",
    "\n",
    "$$\n",
    "\\Theta=\n",
    "\\left[\\begin{array}{ccc}\n",
    "\\theta^{1}& \\cdots&\\theta^{\\lambda}\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "where  $ \\theta^{\\lambda} $ is the output layer "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Input data vector:__\n",
    "\n",
    "$$\n",
    "y^0=\\left[\\begin{array}{ccc}\n",
    "x^T& 1\n",
    "\\end{array}\\right]^T\n",
    "$$\n",
    "it is extended by 1 to allow easier multiplication"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Opertation of a single neuron:__\n",
    "\n",
    "$$\n",
    "y^l_j=\\psi(\\theta^l_j y^{l-1})\n",
    "$$\n",
    "\n",
    "$\\psi$ is the neuron activation function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Output layer:__\n",
    "\n",
    "$$\n",
    "f_j(x, \\Theta)=\\theta^\\lambda_j y^\\lambda\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class MLP():\n",
    "    \"\"\"\n",
    "    todo fully-connected?\n",
    "\n",
    "    Attribubtes:\n",
    "        _layers: \n",
    "\n",
    "    Methods:\n",
    "        fit:\n",
    "    \"\"\"\n",
    "    def __init__(self, dimensions:list, activations:list, derivatives:list, feature_number:int) -> None:\n",
    "        \"\"\"\n",
    "        todo\n",
    "\n",
    "        Args:\n",
    "            dimensions: starting from first hidden layer\n",
    "            activations: last actvation function should be linear if a basic MLP is being modeled\n",
    "\n",
    "        Returns:\n",
    "            MLP object\n",
    "\n",
    "        Raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "\n",
    "        # assertions todo\n",
    "\n",
    "        self._layers = [np.empty((dimensions[0], feature_number + 1))] + \\\n",
    "                       [np.empty((dimensions[i+1], dimensions[i])) for i in range(len(dimensions)-1)]\n",
    "        self._activations = activations\n",
    "\n",
    "    def fit(self):\n",
    "        pass\n",
    "\n",
    "    def feed_forward(self, x):\n",
    "        outputs = x + [1]\n",
    "        for layer, activate in zip(self._layers, self._activations):\n",
    "            outputs = [activate(np.matmul(weights, outputs)) for weights in layer]\n",
    "        return outputs\n",
    "\n",
    "    def backprop(self):\n",
    "        pass\n",
    "\n",
    "    def predict(self, data):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data=[[x, x**2] for x in RNG.uniform(-1, 1, 100)], columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "mlp = MLP([10, 1], [tanh, lambda x: x], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1]\n",
      "[1.14317095e-311 6.17582057e-322]\n",
      "[2.286341896004e-311, 0.0, 1.1609548413287613e-28, 1.0, 1.0, 1.0, 1.0, 1.0, 6.262940465883869e-120, 1.0]\n",
      "[-0.61830633 -0.46423828 -0.98386469  0.9412641   0.03028201  0.85518693\n",
      "  0.86596932  0.9589593   0.94734294  0.11721524]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.7688769007936807]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.feed_forward([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp_env",
   "language": "python",
   "name": "bootcamp_env"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ef482daef44ff0bd9fbee8fa2e0ebe41e796c03537a78bc565ab2ed09fe9d85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
